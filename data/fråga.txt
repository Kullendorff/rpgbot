@bot.command(name="fr√•ga")
    async def fr√•ga(ctx: commands.Context, *, fr√•ga: str) -> None:
    """
    Exempel p√• hur du kan st√§lla fr√•gor via FAISS-indexet.
    """
    await ctx.send("üîç S√∂ker efter relevant information...")

    # 1. S√∂k i FAISS
    relevant_chunks = search_faiss(fr√•ga, top_k=10)
    if not relevant_chunks:
        await ctx.send("‚ö†Ô∏è Hittade ingen relevant information i databasen.")
        return

    # 2. Klistra ihop chunkar till en (relativt) l√•ng text.
    #    Men se upp f√∂r token-gr√§nser. Om du vill kan du g√∂ra en "summarize_chunk"-funktion.
    context_text = "\n\n".join(relevant_chunks)

    # 3. Bygg prompt
    prompt = f"""
    Du √§r en rollspelsexpert. H√§r √§r text fr√•n v√•rt material (PDF:er).
    Anv√§nd endast informationen nedan f√∂r att svara p√• fr√•gan.

    FR√ÖGA: {fr√•ga}

    KONTEXT (relevanta utdrag):
    {context_text}

    Om du inte hittar svaret i utdragen, svara: "Jag hittar inte tillr√§cklig information i materialet."
    """

    # 4. Skicka prompten till GPT-4 (eller GPT-3.5, beroende p√• licens/tillg√•ng)
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "Du √§r en hj√§lpsam rollspelsexpert."},
                {"role": "user", "content": prompt}
            ],
            # (Valfritt) Ange max_tokens, temperature, etc.
        )

        svar = response.choices[0].message.content

        # 5. Splitta svaret i 2000-teckensbitar (pga Discords begr√§nsning).
        for part in split_message(svar):
            await ctx.send(part)

    except Exception as e:
        await ctx.send(f"‚ùå Ett fel uppstod: {str(e)}")
